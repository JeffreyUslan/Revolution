keyval(words, 1)}
#The reducing function to count the words
wc.reduce = function(words, counts ) {
keyval(words, sum(counts))}
# combine the map function and the reduce function
wordcount=function(input,output=NULL){
mapreduce(
input = input,
output = output,
input.format = "text",
map = wc.map,
reduce = wc.reduce,
combine = T)
}
outcome=from.dfs(wordcount(input=romeo_and_juliet))
t=data.frame(key=outcome$key,val=as.numeric(outcome$val))
ord=order(t$val,decreasing=TRUE)
head(t[ord,])
romeo_and_juliet=readLines("./romeo_and_juliet.txt",skipNul = TRUE)
romeo_and_juliet
romeo_and_juliet=readLines("./romeo_and_juliet.txt",skipNul = TRUE)
romeo_and_juliet=as.character(sapply(romeo_and_juliet,function(x) x=iconv(x, "latin1", "ASCII", sub="")))
romeo_and_juliet=as.character(sapply(romeo_and_juliet,function(x) x=gsub("[^[:alpha:] ]", "",x)[[1]]))
romeo_and_juliet=as.character(sapply(romeo_and_juliet,tolower))
romeo_and_juliet=to.dfs(romeo_and_juliet)
#function that encapsulates the job
#     Maps what a word is
wc.map =  function(k, lines) {
words.list=strsplit(x = lines,split = " ")
words=unlist(words.list)
keyval(words, 1)}
#The reducing function to count the words
wc.reduce = function(words, counts ) {
keyval(words, sum(counts))}
# combine the map function and the reduce function
wordcount=function(input,output=NULL){
mapreduce(
input = input,
output = output,
input.format = "text",
map = wc.map,
reduce = wc.reduce,
combine = T)
}
outcome=from.dfs(wordcount(input=romeo_and_juliet))
t=data.frame(key=outcome$key,val=as.numeric(outcome$val))
ord=order(t$val,decreasing=TRUE)
head(t[ord,])
romeo_and_juliet=readLines("./romeo_and_juliet.txt",skipNul = TRUE)
romeo_and_juliet=as.character(sapply(romeo_and_juliet,function(x) x=iconv(x, "latin1", "ASCII", sub="")))
romeo_and_juliet=as.character(sapply(romeo_and_juliet,function(x) x=gsub("[^[:alpha:] ]", "",x)[[1]]))
romeo_and_juliet=as.character(sapply(romeo_and_juliet,tolower))
romeo_and_juliet=to.dfs(romeo_and_juliet)
#function that encapsulates the job
#     Maps what a word is
wc.map =  function(., lines) {
words.list=strsplit(x = lines,split = " ")
words=unlist(words.list)
keyval(words, 1)}
#The reducing function to count the words
wc.reduce = function(words, counts ) {
keyval(words, sum(counts))}
# combine the map function and the reduce function
wordcount=function(input,output=NULL){
mapreduce(
input = input,
output = output,
input.format = "text",
map = wc.map,
reduce = wc.reduce,
combine = T)
}
outcome=from.dfs(wordcount(input=romeo_and_juliet))
t=data.frame(key=outcome$key,val=as.numeric(outcome$val))
ord=order(t$val,decreasing=TRUE)
head(t[ord,])
wordcount=function(input,output=NULL){
mapreduce(
input = input,
output = output,
input.format = "UTF-8",
map = wc.map,
reduce = wc.reduce,
combine = T)
}
outcome=from.dfs(wordcount(input=romeo_and_juliet))
romeo_and_juliet=readLines("./romeo_and_juliet.txt",skipNul = TRUE)
romeo_and_juliet=as.character(sapply(romeo_and_juliet,function(x) x=iconv(x, "latin1", "ASCII", sub="")))
romeo_and_juliet=as.character(sapply(romeo_and_juliet,function(x) x=gsub("[^[:alpha:] ]", "",x)[[1]]))
romeo_and_juliet=as.character(sapply(romeo_and_juliet,tolower))
romeo_and_juliet=to.dfs(romeo_and_juliet)
library(rmr2)
rmr.options(backend="local")
romeo_and_juliet=to.dfs(romeo_and_juliet)
logistic.regression =
function(input, iterations, dims, alpha){
plane = t(rep(0, dims))
g = function(z) 1/(1 + exp(-z))
for (i in 1:iterations) {
gradient =
values(
from.dfs(
mapreduce(
input,
map = lr.map,
reduce = lr.reduce,
combine = T)))
plane = plane + alpha * gradient }
plane }
lr.map =
function(., M) {
Y = M[,1]
X = M[,-1]
keyval(
1,
Y * X *
g(-Y * as.numeric(X %*% t(plane))))}
lr.reduce =
function(k, Z)
keyval(k, t(as.matrix(apply(Z,2,sum))))
#K-means
X=matrix(1:9,nr=3)
X
solve(X)
y=c(1,6,33)
solve(t(X)%*%X, t(X)%*%y)
X[3,3]=30
solve(t(X)%*%X, t(X)%*%y)
X = matrix(rnorm(2000), ncol = 10)
X.index = to.dfs(cbind(1:nrow(X), X))
y = as.matrix(rnorm(200))
solve(t(X)%*%X, t(X)%*%y)
Sum =
function(., YY)
keyval(1, list(Reduce('+', YY)))
XtX =
values(
from.dfs(
mapreduce(
input = X.index,
map =
function(., Xi) {
yi = y[Xi[,1],]
Xi = Xi[,-1]
keyval(1, list(t(Xi) %*% Xi))},
reduce = Sum,
combine = TRUE)))[[1]]
Xty =
values(
from.dfs(
mapreduce(
input = X.index,
map = function(., Xi) {
yi = y[Xi[,1],]
Xi = Xi[,-1]
keyval(1, list(t(Xi) %*% yi))},
reduce = Sum,
combine = TRUE)))[[1]]
solve(XtX, Xty)
dist.fun =
function(C, P) {
apply(
C,
1,
function(x)
colSums((t(P) - x)^2))}
kmeans.map =
function(., P) {
nearest = {
if(is.null(C))
sample(
1:num.clusters,
nrow(P),
replace = T)
else {
D = dist.fun(C, P)
nearest = max.col(-D)}}
if(!(combine || in.memory.combine))
keyval(nearest, P)
else
keyval(nearest, cbind(1, P))}
kmeans.reduce = {
if (!(combine || in.memory.combine) )
function(., P)
t(as.matrix(apply(P, 2, mean)))
else
function(k, P)
keyval(
k,
t(as.matrix(apply(P, 2, sum))))}
kmeans.mr =
function(
P,
num.clusters,
num.iter,
combine,
in.memory.combine) {
C = NULL
for(i in 1:num.iter ) {
C =
values(
from.dfs(
mapreduce(
P,
map = kmeans.map,
reduce = kmeans.reduce)))
if(combine || in.memory.combine)
C = C[, -1]/C[, 1]
if(nrow(C) < num.clusters) {
C =
rbind(
C,
matrix(
rnorm(
(num.clusters -
nrow(C)) * nrow(C)),
ncol = nrow(C)) %*% C) }}
C}
P =
do.call(
rbind,
rep(
list(
matrix(
rnorm(10, sd = 10),
ncol=2)),
20)) +
matrix(rnorm(200), ncol =2)
?combine
??combine
dist.fun =
function(C, P) {
apply(
C,
1,
function(x)
colSums((t(P) - x)^2))}
kmeans.map =
function(., P) {
nearest = {
if(is.null(C))
sample(
1:num.clusters,
nrow(P),
replace = T)
else {
D = dist.fun(C, P)
nearest = max.col(-D)}}
if(!(combine || in.memory.combine))
keyval(nearest, P)
else
keyval(nearest, cbind(1, P))}
kmeans.reduce = {
if (!(combine || in.memory.combine) )
function(., P)
t(as.matrix(apply(P, 2, mean)))
else
function(k, P)
keyval(
k,
t(as.matrix(apply(P, 2, sum))))}
kmeans.mr(
to.dfs(P),
num.clusters = 12,
num.iter = 5,
combine = FALSE,
in.memory.combine = FALSE)
P
kmeans.mr =
function(
P,
num.clusters,
num.iter,
combine,
in.memory.combine) {
## @knitr kmeans-dist.fun
dist.fun =
function(C, P) {
apply(
C,
1,
function(x)
colSums((t(P) - x)^2))}
## @knitr kmeans.map
kmeans.map =
function(., P) {
nearest = {
if(is.null(C))
sample(
1:num.clusters,
nrow(P),
replace = TRUE)
else {
D = dist.fun(C, P)
nearest = max.col(-D)}}
if(!(combine || in.memory.combine))
keyval(nearest, P)
else
keyval(nearest, cbind(1, P))}
## @knitr kmeans.reduce
kmeans.reduce = {
if (!(combine || in.memory.combine) )
function(., P)
t(as.matrix(apply(P, 2, mean)))
else
function(k, P)
keyval(
k,
t(as.matrix(apply(P, 2, sum))))}
## @knitr kmeans-main-1
C = NULL
for(i in 1:num.iter ) {
C =
values(
from.dfs(
mapreduce(
P,
map = kmeans.map,
reduce = kmeans.reduce)))
if(combine || in.memory.combine)
C = C[, -1]/C[, 1]
## @knitr end
#      points(C, col = i + 1, pch = 19)
## @knitr kmeans-main-2
if(nrow(C) < num.clusters) {
C =
rbind(
C,
matrix(
rnorm(
(num.clusters -
nrow(C)) * nrow(C)),
ncol = nrow(C)) %*% C) }}
C}
out = list()
for(be in c("local", "hadoop")) {
rmr.options(backend = be)
set.seed(0)
## @knitr kmeans-data
P =
do.call(
rbind,
rep(
list(
matrix(
rnorm(10, sd = 10),
ncol=2)),
20)) +
matrix(rnorm(200), ncol =2)
## @knitr end
#  x11()
#  plot(P)
#  points(P)
out[[be]] =
## @knitr kmeans-run
kmeans.mr(
to.dfs(P),
num.clusters = 12,
num.iter = 5,
combine = FALSE,
in.memory.combine = FALSE)
## @knitr end
}
romeo_and_juliet=readLines("./romeo_and_juliet.txt",skipNul = TRUE)
romeo_and_juliet=as.character(sapply(romeo_and_juliet,function(x) x=iconv(x, "latin1", "ASCII", sub="")))
romeo_and_juliet=as.character(sapply(romeo_and_juliet,function(x) x=gsub("[^[:alpha:] ]", "",x)[[1]]))
romeo_and_juliet=as.character(sapply(romeo_and_juliet,tolower))
romeo_and_juliet=to.dfs(romeo_and_juliet)
#function that encapsulates the job
#     Maps what a word is
wc.map =  function(., lines) {
words.list=strsplit(x = lines,split = " ")
words=unlist(words.list)
keyval(words, 1)}
#The reducing function to count the words
wc.reduce = function(words, counts ) {
keyval(words, sum(counts))}
# combine the map function and the reduce function
wordcount=function(input,output=NULL){
mapreduce(
input = input,
output = output,
input.format = "text",
map = wc.map,
reduce = wc.reduce,
combine = T)
}
outcome=from.dfs(wordcount(input=romeo_and_juliet))
library(rmr2)
rmr.options(backend="local")
romeo_and_juliet=readLines("./romeo_and_juliet.txt",skipNul = TRUE)
romeo_and_juliet=as.character(sapply(romeo_and_juliet,function(x) x=iconv(x, "latin1", "ASCII", sub="")))
romeo_and_juliet=as.character(sapply(romeo_and_juliet,function(x) x=gsub("[^[:alpha:] ]", "",x)[[1]]))
romeo_and_juliet=as.character(sapply(romeo_and_juliet,tolower))
romeo_and_juliet=to.dfs(romeo_and_juliet)
wc.map =  function(., lines) {
words.list=strsplit(x = lines,split = " ")
words=unlist(words.list)
keyval(words, 1)}
wc.reduce = function(words, counts ) {
keyval(words, sum(counts))}
wordcount=function(input,output=NULL){
mapreduce(
input = input,
output = output,
input.format = "text",
map = wc.map,
reduce = wc.reduce,
combine = T)
}
outcome=from.dfs(wordcount(input=romeo_and_juliet))
library(rhdfs)
install.packages("rhdfs")
install.packages("C:/Users/Jeffrey/Downloads/rhdfs_1.0.8.zip", repos = NULL,type="binary")
library(rhdfs)
Sys.setenv("HADOOP_CMD"="/usr/local/hadoop/bin/hadoop")
library(rhdfs)
Sys.setenv("HADOOP_STREAMING"="/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.4.0.jar")
library(rhdfs)
romeo_and_juliet=readLines("./romeo_and_juliet.txt",skipNul = TRUE)
romeo_and_juliet=as.character(sapply(romeo_and_juliet,function(x) x=iconv(x, "latin1", "ASCII", sub="")))
romeo_and_juliet=as.character(sapply(romeo_and_juliet,function(x) x=gsub("[^[:alpha:] ]", "",x)[[1]]))
romeo_and_juliet=as.character(sapply(romeo_and_juliet,tolower))
hdfs.init()
romeo_and_juliet=to.dfs(romeo_and_juliet)
wc.map =  function(k, lines) {
words.list=strsplit(x = lines,split = " ")
words=unlist(words.list)
keyval(words, 1)}
wc.reduce = function(words, counts ) {
keyval(words, sum(counts))}
wordcount=function(input,output=NULL){
mapreduce(
input = input,
output = output,
input.format = "text",
map = wc.map,
reduce = wc.reduce,
combine = T)
}
outcome=from.dfs(wordcount(input=romeo_and_juliet))
romeo_and_juliet=readLines("./romeo_and_juliet.txt",skipNul = TRUE)
romeo_and_juliet=as.character(sapply(romeo_and_juliet,function(x) x=iconv(x, "latin1", "ASCII", sub="")))
romeo_and_juliet=as.character(sapply(romeo_and_juliet,function(x) x=gsub("[^[:alpha:] ]", "",x)[[1]]))
romeo_and_juliet=as.character(sapply(romeo_and_juliet,tolower))
#function that encapsulates the job
#     Maps what a word is
wc.map =  function(k, lines) {
words.list=strsplit(x = lines,split = " ")
words=unlist(words.list)
keyval(words, 1)}
#The reducing function to count the words
wc.reduce = function(words, counts ) {
keyval(words, sum(counts))}
# combine the map function and the reduce function
wordcount=function(input,output=NULL){
mapreduce(
input = input,
output = output,
map = wc.map,
reduce = wc.reduce,
combine = TRUE)
#       input.format = "text",
}
rmr.options(backend="local")
outcome=from.dfs(wordcount(to.dfs(keyval(NULL,romeo_and_juliet))))
outcome
t=data.frame(key=outcome$key,val=as.numeric(outcome$val))
ord=order(t$val,decreasing=TRUE)
head(t[ord,])
t[ord,1:50]
dim(t)
t[ord,]
t[ord,][1:50,]
?strlen
head(sapply(t,nchar))
class(t)
dim(t)
lengths=sapply(t[,1],nchar)
class(t[,1])
class(t[,2])
class(t[,1])="character"
t[ord,][1:50,]
t=data.frame(key=outcome$key,val=as.numeric(outcome$val))
t[ord,][1:50,]
class(t[,1])
head(as.character(t[,1]))
t[,1]=as.character(t[,1])
t[ord,][1:50,]
lengths=sapply(t[,1],nchar)
head(lengths)
t[ord,][which(lengths>2),][1:50,]
t=data.frame(key=outcome$key,val=as.numeric(outcome$val))
t[,1]=as.character(t[,1])
lengths=sapply(t[,1],nchar)
t=t[which(lengths>2),]
ord=order(t$val,decreasing=TRUE)
t[ord,][1:50,]
t=data.frame(key=outcome$key,val=as.numeric(outcome$val))
t[,1]=as.character(t[,1])
lengths=sapply(t[,1],nchar)
t=t[which(lengths>3),]
ord=order(t$val,decreasing=TRUE)
t[ord,][1:50,]
t=data.frame(key=outcome$key,val=as.numeric(outcome$val))
t[,1]=as.character(t[,1])
lengths=sapply(t[,1],nchar)
t=t[which(lengths>4),]
ord=order(t$val,decreasing=TRUE)
t[ord,][1:50,]
row.names(t)=NULL
t[ord,][1:50,]
