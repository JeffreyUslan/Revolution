{
    "contents" : "# https://github.com/RevolutionAnalytics/rmr2/blob/master/docs/tutorial.md\nlibrary(rmr2)\nrmr.options(backend=\"local\")\n\n##Squaring\n#normal\nsmall.ints = 1:1000\ncbind(small.ints,sapply(small.ints, function(x) x^2))\n\n#mapreduce\nsmall.ints = to.dfs(1:1000)\nfrom.dfs(\n  mapreduce(\n    input = small.ints, \n    map = function(k, v) cbind(v, v^2)\n  )\n)\n\n\n\n##Length Counting\n# send groups ID (randomly generated from a binomial) to Hadoop filesystem\ngroups = rbinom(32, n = 15, prob = 0.4)\nt=tapply(groups, groups, length)\n\n\ngroups = to.dfs(groups)\n# run a mapreduce job\n## map: key value is the group id, value is 1\n## reduce: count the number of observations in each group\n## then, retrieve it from Hadoop filesystem\noutput = from.dfs(\n  mapreduce(input = groups, \n            map = function(., v) \n              keyval(v, 1), \n            reduce = function(k, vv)  \n              keyval(k, length(vv))\n  )\n)\n# print results\n## keys: group IDs\n## values: results of reduce job (<em>i.e.</em>, frequency)\nt(data.frame(key=output$key,val=output$val))\nt\n\n#broken ##Word Count\n\n\nromeo_and_juliet=readLines(\"./romeo_and_juliet.txt\",skipNul = TRUE)\nromeo_and_juliet=as.character(sapply(romeo_and_juliet,function(x) x=iconv(x, \"latin1\", \"ASCII\", sub=\"\")))\nromeo_and_juliet=as.character(sapply(romeo_and_juliet,function(x) x=gsub(\"[^[:alpha:] ]\", \"\",x)[[1]]))\nromeo_and_juliet=as.character(sapply(romeo_and_juliet,tolower))\n\n\n\n\n\n\n#function that encapsulates the job\n#     Maps what a word is\nwc.map =  function(k, lines) {\n  words.list=strsplit(x = lines,split = \" \")\n  words=unlist(words.list)\n  keyval(words, 1)}\n#The reducing function to count the words\nwc.reduce = function(words, counts ) {\n  keyval(words, sum(counts))}\n# combine the map function and the reduce function\nwordcount=function(input,output=NULL){\n  mapreduce(\n    input = input,\n    output = output,\n    \n    map = wc.map,\n    reduce = wc.reduce,\n    combine = TRUE)\n  #       input.format = \"text\",\n}\n\n\noutcome=from.dfs(wordcount(to.dfs(keyval(NULL,romeo_and_juliet))))\nt=data.frame(key=outcome$key,val=as.numeric(outcome$val))\nt[,1]=as.character(t[,1])\nlengths=sapply(t[,1],nchar)\nt=t[which(lengths>4),]\nord=order(t$val,decreasing=TRUE)\nt[ord,][1:50,]\n\n# Logistic Regression\nlibrary(rmr2)\n\nlogistic.regression = \n  function(input, iterations, dims, alpha){\n    \n    ## Map function- makes a subset grid\n    lr.map =  function(., M) {\n      Y = M[,1] \n      X = M[,-1]\n      keyval(\n        1,\n        Y * X * \n          g(-Y * as.numeric(X %*% t(plane))))\n    }\n    ## Reduce Function sum the dubset grids contribution\n    lr.reduce = function(k, Z) {\n      keyval(k, t(as.matrix(apply(Z,2,sum))))\n    }\n    \n    \n    ## Sigmoid Function\n    g = function(z) {\n      1/(1 + exp(-z))\n    }\n    #A vector to hold coefficients\n    plane = t(rep(0, dims))\n    \n    #Iterating \n    for (i in 1:iterations) {\n      gradient = \n        values(\n          from.dfs(\n            mapreduce(\n              input,\n              map = lr.map,     \n              reduce = lr.reduce,\n              combine = TRUE)))\n      plane = plane + alpha * gradient }\n    plane }\n\ntest.size = 10^5\neps = rnorm(test.size)\ntestdata = \n  to.dfs(\n    as.matrix(\n      data.frame(\n        y = 2 * (eps > 0) - 1,\n        x1 = 1:test.size, \n        x2 = 1:test.size + eps)))\n\nlogistic.regression(testdata, 3, 2, 0.05)\n\n## K-means\n#A wrapper function\nkmeans.mr = \n  function(\n    P, \n    num.clusters, \n    num.iter, \n    combine, \n    in.memory.combine) {\n    #Calculate the distances\n    dist.fun = \n      function(C, P) {\n        apply(\n          C,\n          1, \n          function(x) \n            colSums((t(P) - x)^2))}\n    # Map function, samples different chunks of data\n    kmeans.map = \n      function(., P) {\n        nearest = {\n          if(is.null(C)) \n            sample(\n              1:num.clusters, \n              nrow(P), \n              replace = TRUE)\n          else {\n            D = dist.fun(C, P)\n            nearest = max.col(-D)}}\n        if(!(combine || in.memory.combine))\n          keyval(nearest, P) \n        else \n          keyval(nearest, cbind(1, P))}\n    \n    \n    # Reduce function, accumulates distances from map function\n    kmeans.reduce = {\n      if (!(combine || in.memory.combine) ) \n        function(., P) \n          t(as.matrix(apply(P, 2, mean)))\n      else \n        function(k, P) \n          keyval(\n            k, \n            t(as.matrix(apply(P, 2, sum))))}\n    \n    # Iterating function\n    C = NULL\n    for(i in 1:num.iter ) {\n      C = \n        values(\n          from.dfs(\n            mapreduce(\n              P, \n              map = kmeans.map,\n              reduce = kmeans.reduce)))\n      if(combine || in.memory.combine)\n        C = C[, -1]/C[, 1]\n      \n      if(nrow(C) < num.clusters) {\n        C = \n          rbind(\n            C,\n            matrix(\n              rnorm(\n                (num.clusters - \n                   nrow(C)) * nrow(C)), \n              ncol = nrow(C)) %*% C) }}\n    C}\n\n#Creating example\nset.seed(3)\nP = \n  do.call(\n    rbind, \n    rep(\n      list(\n        matrix(\n          rnorm(10, sd = 10), \n          ncol=2)), \n      20)) + \n  matrix(rnorm(200), ncol =2)\n\nplot(P)\noutcome=    kmeans.mr(\n  to.dfs(P),\n  num.clusters = 4, \n  num.iter = 5,\n  combine = FALSE,\n  in.memory.combine = FALSE)\n\n#compare mapreduce to kmeans function\nclust_ind=apply(P,1,function(x){\n  sub_dist=apply(outcome,1,function(y){\n    sqrt((y[1]-x[1])^2+(y[2]-x[2])^2)\n  })\n  which(sub_dist==min(sub_dist))\n})\nP=as.data.frame(P)\nP[,3]=clust_ind\n\n\nk=kmeans(as.matrix(P[,1:2]),4)\nP[,4]=k$cluster\ntable(P$V3,P$V4)\nlibrary(ggplot2)\nggplot(P)+geom_point(aes(x=V1,y=V2),colour=P[,3])\nggplot(P)+geom_point(aes(x=V1,y=V2),colour=P[,4])\n\n##Linear Least Squares\n\nsolve(t(X)%*%X, t(X)%*%y)\n\nX = matrix(rnorm(2000), ncol = 10)\nX.index = to.dfs(cbind(1:nrow(X), X))\ny = as.matrix(rnorm(200))\n\n\nSum = \n  function(., YY) \n    keyval(1, list(Reduce('+', YY)))\n\n\nXtX = \n  values(\n    from.dfs(\n      mapreduce(\n        input = X.index,\n        map = \n          function(., Xi) {\n            yi = y[Xi[,1],]\n            Xi = Xi[,-1]\n            keyval(1, list(t(Xi) %*% Xi))},\n        reduce = Sum,\n        combine = TRUE)))[[1]]\n\nXty = \n  values(\n    from.dfs(\n      mapreduce(\n        input = X.index,\n        map = function(., Xi) {\n          yi = y[Xi[,1],]\n          Xi = Xi[,-1]\n          keyval(1, list(t(Xi) %*% yi))},\n        reduce = Sum,\n        combine = TRUE)))[[1]]\n\nsolve(XtX, Xty)\n\n\n\n",
    "created" : 1433524653290.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1047532615",
    "id" : "B88E706C",
    "lastKnownWriteTime" : 1433963781,
    "path" : "~/Revolution/rmr_examples.R",
    "project_path" : "rmr_examples.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}